{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOhT1WmGVKXvDd/qnCX0hW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Renan-Domingues/IntroductionToPytorch/blob/main/IntorductionPytorch_06_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training with PyTorch\n"
      ],
      "metadata": {
        "id": "hQ8H_QDpUjbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We'll get familiar with dataset and dataLoader abstraction\n",
        "- We'll discuss specific loss functions and when use them\n",
        "- We'll look at PyTorch Optimizers,  witch adjust model weights based the loss function outcome\n"
      ],
      "metadata": {
        "id": "KSBHVugsU214"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset and DataLoader\n",
        "\n",
        "The dataset and dataLoader classes encapsulate the processing of pulling our data from the storage and exposing it to the training loop in batches\n",
        "\n",
        "The Dataset is responsible for accessing and processing single instances of data\n",
        "\n",
        "The DataLoader pulls instances of data from dataset, collects them in batches, and return them for consumption by your training loop"
      ],
      "metadata": {
        "id": "mh7VKRqdVf1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# PyTorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5), (0.5))]\n",
        ")\n",
        "\n",
        "# Create datasets for training & validation, download if necessary\n",
        "training_set = torchvision.datasets.FashionMNIST('./data',\n",
        "                                                 train=True,\n",
        "                                                 transform=transform,\n",
        "                                                 download=True)\n",
        "\n",
        "validation_set = torchvision.datasets.FashionMNIST('./data',\n",
        "                                                   train=False,\n",
        "                                                   transform=transform,\n",
        "                                                   download=True)\n",
        "\n",
        "# Create data loaders, shuffle for training but not for validation\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(training_set,\n",
        "                                              batch_size=4,\n",
        "                                              shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set,\n",
        "                                                batch_size=4,\n",
        "                                                shuffle=False)\n",
        "\n",
        "# Class labels\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "# Report split sizes\n",
        "print(f'training set has {len(training_set)} instances')\n",
        "print(f'Validation set has {len(validation_set)} instances')"
      ],
      "metadata": {
        "id": "qweQpchLWaST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c597c0d6-00bd-45a8-b87d-3dd218ba7142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 14948184.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 266935.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5024223.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 13126004.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "training set has 60000 instances\n",
            "Validation set has 10000 instances\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# helper function for inline image display\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "  if one_channel:\n",
        "    img = img.mean(dim=0)\n",
        "  img = img / 2 + 0.5 # unnormalize\n",
        "  npimg = img.numpy()\n",
        "  if one_channel:\n",
        "    plt.imshow(npimg, cmap=\"Greys\")\n",
        "  else:\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# create a grid from the images and show them\n",
        "img_grid = torchvision.utils. make_grid(images)\n",
        "matplotlib_imshow(img_grid, one_channel=True)\n",
        "print(' '.join(classes[labels[j]] for j in range(4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "En6szatBjEgl",
        "outputId": "87329488-19ae-4b49-f51b-26b10ca9d307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coat Sandal Coat Sandal\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Model"
      ],
      "metadata": {
        "id": "Q9rgBYNZkk_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# PyTorch models inherit from torch.nn.Module\n",
        "class GarmentClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GarmentClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = GarmentClassifier()\n"
      ],
      "metadata": {
        "id": "nALI81y9kqzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss Function\n",
        "\n",
        "For demonstration purposes, we'll create batches of dummy output and label values, run them through the loss function, and examine the result."
      ],
      "metadata": {
        "id": "rqkrr40xmZT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use the cross-entropy loss\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Loss function expect data in batches, so we're creating batches of 4\n",
        "dummy_outputs = torch.rand(4, 10)\n",
        "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
        "\n",
        "print(dummy_outputs)\n",
        "print(dummy_labels)\n",
        "\n",
        "loss = loss_fn(dummy_outputs, dummy_labels)\n",
        "print(f'Total loss for this batch {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzLlMDgfmjqH",
        "outputId": "2ebdec29-d8fb-4955-b207-91b5297a4acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2743, 0.4102, 0.6050, 0.1525, 0.0546, 0.3288, 0.7227, 0.4026, 0.5552,\n",
            "         0.5784],\n",
            "        [0.5115, 0.6881, 0.2108, 0.5930, 0.7337, 0.4290, 0.9829, 0.6173, 0.9984,\n",
            "         0.0166],\n",
            "        [0.8128, 0.3581, 0.3261, 0.4107, 0.2350, 0.6834, 0.0113, 0.4701, 0.6434,\n",
            "         0.6005],\n",
            "        [0.5076, 0.0376, 0.9616, 0.8752, 0.0828, 0.0604, 0.7334, 0.7538, 0.4191,\n",
            "         0.0747]])\n",
            "tensor([1, 5, 3, 7])\n",
            "Total loss for this batch 2.3112785816192627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer\n",
        "\n",
        "We'll  use the stochastic gradient descent woth momentum.\n",
        "\n",
        "momentum - it push the optimizer in the direction of strongest gradient over multiple steps\n"
      ],
      "metadata": {
        "id": "178jRDoHnulM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "LBM9PerUsnvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Training Loop\n",
        "\n",
        "what is happening in each pass of the loop:\n",
        "\n",
        "\n",
        "\n",
        "- Gets a batch of training data from the DataLoader\n",
        "\n",
        "- Zeros the optimizer's gradients\n",
        "\n",
        "- Performs an inference - that is, gets predictions from the model for an input batch\n",
        "\n",
        "- Calculates the loss for that set of predictions vs. the labels on the dataset\n",
        "\n",
        "- Calculates the backward gradients over the learning weights\n",
        "\n",
        "- Tells the optimizer to perform one learning step - that is, adjust the model's learning weights based on the observed gradients for this batch, according to the optimization algorithm we chose\n",
        "\n",
        "- It reports on the loss for every 1000 batches.\n",
        "\n",
        "- Finally, it reports the average per-batch loss for the last 1000 batches, for comparison with a validation run\n"
      ],
      "metadata": {
        "id": "CVbEV0SAs1qG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n",
        "  running_loss = 0\n",
        "  last_loss = 0\n",
        "\n",
        "  for i, data in enumerate(training_loader):\n",
        "    # Every data instance is an input + label pair\n",
        "    inputs, labels = data\n",
        "\n",
        "    #zero the gradients for every batch\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Make prediction for this batch\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # compute the loss and its gradients\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    loss.backward()\n",
        "\n",
        "    # adjust the learning weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # Gather data and report\n",
        "    running_loss += loss.item()\n",
        "    if i % 1000 == 999:\n",
        "      last_loss = running_loss / 1000 # loss per batch\n",
        "      print(f' batch: {i + 1} loss: {last_loss}')\n",
        "      tb_x = epoch_index * len(training_loader) + i + 1\n",
        "      tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "      running_loss = 0.\n",
        "\n",
        "  return last_loss"
      ],
      "metadata": {
        "id": "lO6tCTdSuH99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Per-Epoch Activity\n",
        "\n",
        "Here, we'll do our reporting in TensorBoard. This will require going to the command line to start TensorBoard, and opening it in another browser tab."
      ],
      "metadata": {
        "id": "uFwAY1tUwPqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter(f'runs/fashion_trainer_{timestamp}')\n",
        "epoch_number = 0\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "\n",
        "for epoch  in range(EPOCHS):\n",
        "  print(f'EPOCH {epoch_number + 1}')\n",
        "\n",
        "  model.train(True)\n",
        "  avg_loss = train_one_epoch(epoch_number, writer)\n",
        "\n",
        "  running_vloss = 0.0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, vdata in  enumerate(validation_loader):\n",
        "      vinputs, vlabels = vdata\n",
        "      voutputs = model(vinputs)\n",
        "      vloss = loss_fn(voutputs, vlabels)\n",
        "      running_vloss += vloss\n",
        "\n",
        "  avg_vloss = running_vloss / (i + 1)\n",
        "  print(f\" LOSS train {avg_loss} valid {avg_vloss}\")\n",
        "\n",
        "  writer.add_scalars('training vcs validation loss',\n",
        "                     {'training': avg_loss, 'Validation': avg_vloss},\n",
        "                     epoch_number + 1)\n",
        "  writer.flush()\n",
        "\n",
        "  if avg_vloss < best_vloss:\n",
        "    best_vloss = avg_vloss\n",
        "    model_path = f'model_{timestamp}_{epoch_number}'\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "\n",
        "  epoch_number += 1\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4G1vkF5wjyj",
        "outputId": "7d1a8bb6-9685-4892-f8e7-938d33165b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1\n",
            " batch: 1000 loss: 1.7072935178428887\n",
            " batch: 2000 loss: 0.8224790668487549\n",
            " batch: 3000 loss: 0.7125203360076994\n",
            " batch: 4000 loss: 0.6510529834385961\n",
            " batch: 5000 loss: 0.6054272835507291\n",
            " batch: 6000 loss: 0.5682494880040176\n",
            " batch: 7000 loss: 0.5584115169532597\n",
            " batch: 8000 loss: 0.5145772430835059\n",
            " batch: 9000 loss: 0.4899272675893735\n",
            " batch: 10000 loss: 0.4878806865841616\n",
            " batch: 11000 loss: 0.4642151725580916\n",
            " batch: 12000 loss: 0.44265515326836613\n",
            " batch: 13000 loss: 0.45018164464685834\n",
            " batch: 14000 loss: 0.428365321966121\n",
            " batch: 15000 loss: 0.40540716868510934\n",
            " LOSS train 0.40540716868510934 valid 0.45086997747421265\n",
            "EPOCH 2\n",
            " batch: 1000 loss: 0.3844018662413728\n",
            " batch: 2000 loss: 0.3927876336658992\n",
            " batch: 3000 loss: 0.41265662166522815\n",
            " batch: 4000 loss: 0.3989526324522449\n",
            " batch: 5000 loss: 0.3560462340557133\n",
            " batch: 6000 loss: 0.382255077167054\n",
            " batch: 7000 loss: 0.38062660212029004\n",
            " batch: 8000 loss: 0.38010720060544556\n",
            " batch: 9000 loss: 0.368526779780339\n",
            " batch: 10000 loss: 0.4005032149861654\n",
            " batch: 11000 loss: 0.37165315732866294\n",
            " batch: 12000 loss: 0.331398188486477\n",
            " batch: 13000 loss: 0.3306239563116105\n",
            " batch: 14000 loss: 0.3642571286476159\n",
            " batch: 15000 loss: 0.3821472530669998\n",
            " LOSS train 0.3821472530669998 valid 0.36984482407569885\n",
            "EPOCH 3\n",
            " batch: 1000 loss: 0.3299265910263639\n",
            " batch: 2000 loss: 0.3557590234883974\n",
            " batch: 3000 loss: 0.33802120556756565\n",
            " batch: 4000 loss: 0.3239811198210082\n",
            " batch: 5000 loss: 0.33474059918127025\n",
            " batch: 6000 loss: 0.3338755246130167\n",
            " batch: 7000 loss: 0.3256306523894018\n",
            " batch: 8000 loss: 0.3184903038263292\n",
            " batch: 9000 loss: 0.32228180321089167\n",
            " batch: 10000 loss: 0.32700484058118306\n",
            " batch: 11000 loss: 0.31500281857709345\n",
            " batch: 12000 loss: 0.2941883178410644\n",
            " batch: 13000 loss: 0.311288167977822\n",
            " batch: 14000 loss: 0.3407053591310396\n",
            " batch: 15000 loss: 0.3130133552176994\n",
            " LOSS train 0.3130133552176994 valid 0.3358522951602936\n",
            "EPOCH 4\n",
            " batch: 1000 loss: 0.2831269090084979\n",
            " batch: 2000 loss: 0.30244102722785826\n",
            " batch: 3000 loss: 0.29448298726422945\n",
            " batch: 4000 loss: 0.28133062615831295\n",
            " batch: 5000 loss: 0.29881426291815294\n",
            " batch: 6000 loss: 0.29031339604019013\n",
            " batch: 7000 loss: 0.31594020786920735\n",
            " batch: 8000 loss: 0.2993341725288519\n",
            " batch: 9000 loss: 0.3301769840985944\n",
            " batch: 10000 loss: 0.28689647393229095\n",
            " batch: 11000 loss: 0.2991365186069961\n",
            " batch: 12000 loss: 0.31270601506398815\n",
            " batch: 13000 loss: 0.2994609999606182\n",
            " batch: 14000 loss: 0.2881392179226259\n",
            " batch: 15000 loss: 0.28493235881067813\n",
            " LOSS train 0.28493235881067813 valid 0.3311558663845062\n",
            "EPOCH 5\n",
            " batch: 1000 loss: 0.2836076082334439\n",
            " batch: 2000 loss: 0.27269469878911334\n",
            " batch: 3000 loss: 0.28941501294703265\n",
            " batch: 4000 loss: 0.2914640370084071\n",
            " batch: 5000 loss: 0.27620687169616215\n",
            " batch: 6000 loss: 0.2690915099869235\n",
            " batch: 7000 loss: 0.281758658177343\n",
            " batch: 8000 loss: 0.27261783814521734\n",
            " batch: 9000 loss: 0.27592583308229895\n",
            " batch: 10000 loss: 0.2945868447008033\n",
            " batch: 11000 loss: 0.25930182022376175\n",
            " batch: 12000 loss: 0.2754945319364269\n",
            " batch: 13000 loss: 0.27979319413201303\n",
            " batch: 14000 loss: 0.27996515681647\n",
            " batch: 15000 loss: 0.2805395285858394\n",
            " LOSS train 0.2805395285858394 valid 0.31661471724510193\n"
          ]
        }
      ]
    }
  ]
}