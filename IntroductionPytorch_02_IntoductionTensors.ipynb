{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP9TbydLF5cPSY7vs+gZmXv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Renan-Domingues/IntroductionToPytorch/blob/main/IntroductionPytorch_02_IntoductionTensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Pytorch Tensors\n",
        "Tensors are the central data abstraction in PyTorch"
      ],
      "metadata": {
        "id": "jnjyiWFS6ELv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math"
      ],
      "metadata": {
        "id": "Epqqpd_E6VuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The simplest way to create a tensor is with the torch.empty() call\n",
        "\n",
        "x = torch.empty(3, 4)\n",
        "print(type(x))\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04wcN_r36aV3",
        "outputId": "dbdf64b5-6aa1-4a61-9eda-e19a4c46731b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[0.0000e+00, 0.0000e+00, 1.8077e-43, 0.0000e+00],\n",
            "        [5.3858e-38, 4.4445e-41, 5.3858e-38, 4.4445e-41],\n",
            "        [1.4013e-45,        nan, 1.4013e-45, 8.4078e-45]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- this tensor is 2 dimensional,  having 3 rows and 4 columns.\n",
        "- the return (torch.Tensor) is an alias for torch.FloatTensor.\n",
        "- this random numbers is because torch.empty() call alocates memory for the tensor, but does not initialize in with any values (this number are memory at the time of allocation)\n",
        "\n",
        "\n",
        "Brif note about tensors\n",
        "\n",
        "- one dimensional tensor is called a vector\n",
        "- 2 dimensional tensor is a matrix\n",
        "- anything with more than 2 dimensional os kist called a tensor"
      ],
      "metadata": {
        "id": "lI-JrdE-7GAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's create some tensors with values\n",
        "\n",
        "zeros = torch.zeros(2, 3)\n",
        "print(zeros)\n",
        "\n",
        "ones = torch.ones(2, 3)\n",
        "print(ones)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "random = torch.rand(2, 3)\n",
        "print(random)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "445a7-H88UiX",
        "outputId": "9a833e3e-490c-4fdc-ca8f-5f5e3e3e3dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[0.8823, 0.9150, 0.3829],\n",
            "        [0.9593, 0.3904, 0.6009]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Tensors and Seeding\n"
      ],
      "metadata": {
        "id": "H8M20AGk8yyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we are going to use manual_seed() to have the same random value\n",
        "\n",
        "torch.manual_seed(1729)\n",
        "random1 = torch.rand(2, 3)\n",
        "print(random1)\n",
        "\n",
        "random2 = torch.rand(2, 3)\n",
        "print(random2)\n",
        "\n",
        "torch.manual_seed(1729)\n",
        "random3 = torch.rand(2, 3)\n",
        "print(random3)\n",
        "\n",
        "random4 = torch.rand(2, 3)\n",
        "print(random4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb_2B0NT89cF",
        "outputId": "12af4703-55ce-4bb9-ebca-7068dbd59e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3126, 0.3791, 0.3087],\n",
            "        [0.0736, 0.4216, 0.0691]])\n",
            "tensor([[0.2332, 0.4047, 0.2162],\n",
            "        [0.9927, 0.4128, 0.5938]])\n",
            "tensor([[0.3126, 0.3791, 0.3087],\n",
            "        [0.0736, 0.4216, 0.0691]])\n",
            "tensor([[0.2332, 0.4047, 0.2162],\n",
            "        [0.9927, 0.4128, 0.5938]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor shapes\n",
        "when performing operations, often we need to have the same tensor shape - that means, having the same number of dimensions and the same number of cells in each dimension\n",
        "\n",
        "for that, we have the ``torch.*_like()`` methods:"
      ],
      "metadata": {
        "id": "o67iI_I39-hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(2, 2, 3)\n",
        "print(x.shape)\n",
        "print(x)\n",
        "\n",
        "empty_like_x = torch.empty_like(x)\n",
        "print(empty_like_x.shape)\n",
        "print(empty_like_x)\n",
        "\n",
        "zeros_like_x = torch.zeros_like(x)\n",
        "print(zeros_like_x.shape)\n",
        "print(zeros_like_x)\n",
        "\n",
        "ones_like_x = torch.ones_like(x)\n",
        "print(ones_like_x.shape)\n",
        "print(ones_like_x)\n",
        "\n",
        "rand_like_x = torch.rand_like(x)\n",
        "print(rand_like_x.shape)\n",
        "print(rand_like_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FltWg_n-myy",
        "outputId": "aef3e46b-5fce-446b-9be3-056eda1e1fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3])\n",
            "tensor([[[3.4648e+30, 3.3149e-41, 3.4657e+30],\n",
            "         [3.3149e-41, 4.2160e-01, 6.9054e-02]],\n",
            "\n",
            "        [[0.0000e+00, 0.0000e+00, 9.8091e-45],\n",
            "         [8.4078e-45, 9.8091e-45, 1.4013e-44]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[ 5.3858e-38,  4.4445e-41,  3.4588e+30],\n",
            "         [ 3.3149e-41,  4.4842e-44,  0.0000e+00]],\n",
            "\n",
            "        [[ 1.5695e-43,  0.0000e+00, -3.1639e-07],\n",
            "         [ 3.3156e-41,  0.0000e+00,  0.0000e+00]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[1., 1., 1.],\n",
            "         [1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1.],\n",
            "         [1., 1., 1.]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[0.6128, 0.1519, 0.0453],\n",
            "         [0.5035, 0.9978, 0.3884]],\n",
            "\n",
            "        [[0.6929, 0.1703, 0.1384],\n",
            "         [0.4759, 0.7481, 0.0361]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the code ``.shape`` property. Shows the shape of a tensor,  in this case: [2, 2, 3] 1st=dimension, 2nd=rows, 3rd=columns.\n",
        "\n",
        "using the ``.empty_like(), .zeros_like(), .ones_like(), .rand_like()`` it returns a tensor with identical dimensionality and extend"
      ],
      "metadata": {
        "id": "Ba3OlfyR_0lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this way of creating a tensor will especify its data from PyTorch collection\n",
        "\n",
        "some_constants = torch.tensor([[3.1415926, 2.71828], [1.61803, 0.0072897]])\n",
        "print(some_constants)\n",
        "\n",
        "some_integers = torch.tensor((2, 3, 5, 7, 11, 13, 17, 19))\n",
        "print(some_integers)\n",
        "\n",
        "more_integers = torch.tensor(((2, 4, 6), [3, 6, 9]))\n",
        "print(more_integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnRgi3PRAwMV",
        "outputId": "cdb622a5-0af7-47bd-81eb-088d42742c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3.1416, 2.7183],\n",
            "        [1.6180, 0.0073]])\n",
            "tensor([ 2,  3,  5,  7, 11, 13, 17, 19])\n",
            "tensor([[2, 4, 6],\n",
            "        [3, 6, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using torch.tensor() is the  most straightforward way to create a tensor if you already have data in a Pyton tuple or list"
      ],
      "metadata": {
        "id": "ise5H0I6Bub9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Data Types"
      ],
      "metadata": {
        "id": "aPI9qWU7C3dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones((2, 3), dtype=torch.int16)\n",
        "print(a)\n",
        "\n",
        "b = torch.rand((2, 3), dtype=torch.float64) * 20.\n",
        "print(b)\n",
        "\n",
        "c = b.to(torch.int32)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgqzLXIsC7cR",
        "outputId": "5e919c6b-c4cc-4489-e91c-000d3a1ad4f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1]], dtype=torch.int16)\n",
            "tensor([[ 0.9956,  1.4148,  5.8364],\n",
            "        [11.2406, 11.2083, 11.6692]], dtype=torch.float64)\n",
            "tensor([[ 0,  1,  5],\n",
            "        [11, 11, 11]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Math and Logic with Pytorch Tensors"
      ],
      "metadata": {
        "id": "L5gugMR6G4ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.zeros(2, 2) + 1\n",
        "twos = torch.ones(2, 2) * 2\n",
        "threes = (torch.ones(2, 2) * 7 - 1) / 2\n",
        "fours = twos ** 2\n",
        "sqrt2s = twos ** 0.5\n",
        "\n",
        "print(ones)\n",
        "print(twos)\n",
        "print(threes)\n",
        "print(fours)\n",
        "print(sqrt2s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ty55SrWHA4S",
        "outputId": "9a23403e-93b5-417d-ab3c-f9ae4dd94e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[2., 2.],\n",
            "        [2., 2.]])\n",
            "tensor([[3., 3.],\n",
            "        [3., 3.]])\n",
            "tensor([[4., 4.],\n",
            "        [4., 4.]])\n",
            "tensor([[1.4142, 1.4142],\n",
            "        [1.4142, 1.4142]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "powers2 = twos ** torch.tensor([[1, 2],  [3, 4]])\n",
        "print(powers2)\n",
        "\n",
        "fives = ones + fours\n",
        "print(fives)\n",
        "\n",
        "dozens = threes * fours\n",
        "print(dozens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-g0UGF6H7pH",
        "outputId": "96608d41-68f1-4e8e-cc49-3afa111503cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.,  4.],\n",
            "        [ 8., 16.]])\n",
            "tensor([[5., 5.],\n",
            "        [5., 5.]])\n",
            "tensor([[12., 12.],\n",
            "        [12., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A intentional error (to show diferent dimensions)\n",
        "\n",
        "a = torch.rand(2, 3)\n",
        "b = torch.rand(3, 2)\n",
        "\n",
        "print( a * b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "r8WIUCNXIf4f",
        "outputId": "4feb0e5b-2366-4cc0-da87-29b12d609883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-177ffe3381bf>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The exception to same-shapes rule is tensor broadcasting\n",
        "\n",
        "rand = torch.rand(2, 4)\n",
        "doubled = rand * (torch.ones(1, 4) * 2)\n",
        "\n",
        "print(rand)\n",
        "print(doubled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPfE-s9vI1n3",
        "outputId": "bc1b4380-6d8c-4eb2-f331-b429c01582c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2024, 0.5731, 0.7191, 0.4067],\n",
            "        [0.7301, 0.6276, 0.7357, 0.0381]])\n",
            "tensor([[0.4049, 1.1461, 1.4382, 0.8134],\n",
            "        [1.4602, 1.2551, 1.4715, 0.0762]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this case they have similarities in their shapes.\n",
        "in the exemple above, the (1, 4)tensor is multiplied by both rows of the (2, 4)tensor\n",
        "\n",
        "this example of (2, 4) * (1, 4) returned a tensor of shape (2, 4)\n",
        "\n",
        "The rules of broadcasting are\n",
        "- Each tensor  must have at least one dimension - no empty tensors.\n",
        "- Comparing the dimension sizes of the two tensors, going from last to first\n",
        "    - Each dimension must be equal, or\n",
        "    - One of the dimensions must be of size 1, or\n",
        "    - The dimension does not exist in one of the tensors\n",
        "\n"
      ],
      "metadata": {
        "id": "M4gYb3lNKq8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some examples of the rules that allow broadcasting\n",
        "\n",
        "a = torch.ones(4, 3, 2)\n",
        "\n",
        "b = a * torch.rand(3, 2) # 3rd and 2nd dims identical to a, dim 1 absent\n",
        "print(b)\n",
        "\n",
        "c = a * torch.rand(3, 1) # 3rd dim = 1, 2nd dim identical to a\n",
        "print(c)\n",
        "\n",
        "d = a * torch.rand(1, 2)  # 3rd dim identical to a, 2nd dim = 1\n",
        "print(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXDL7OUcMZ72",
        "outputId": "eb4bef2a-5ae3-4126-9a56-e697c7a26173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.2138, 0.5395],\n",
            "         [0.3686, 0.4007],\n",
            "         [0.7220, 0.8217]],\n",
            "\n",
            "        [[0.2138, 0.5395],\n",
            "         [0.3686, 0.4007],\n",
            "         [0.7220, 0.8217]],\n",
            "\n",
            "        [[0.2138, 0.5395],\n",
            "         [0.3686, 0.4007],\n",
            "         [0.7220, 0.8217]],\n",
            "\n",
            "        [[0.2138, 0.5395],\n",
            "         [0.3686, 0.4007],\n",
            "         [0.7220, 0.8217]]])\n",
            "tensor([[[0.2612, 0.2612],\n",
            "         [0.7375, 0.7375],\n",
            "         [0.8328, 0.8328]],\n",
            "\n",
            "        [[0.2612, 0.2612],\n",
            "         [0.7375, 0.7375],\n",
            "         [0.8328, 0.8328]],\n",
            "\n",
            "        [[0.2612, 0.2612],\n",
            "         [0.7375, 0.7375],\n",
            "         [0.8328, 0.8328]],\n",
            "\n",
            "        [[0.2612, 0.2612],\n",
            "         [0.7375, 0.7375],\n",
            "         [0.8328, 0.8328]]])\n",
            "tensor([[[0.8444, 0.2941],\n",
            "         [0.8444, 0.2941],\n",
            "         [0.8444, 0.2941]],\n",
            "\n",
            "        [[0.8444, 0.2941],\n",
            "         [0.8444, 0.2941],\n",
            "         [0.8444, 0.2941]],\n",
            "\n",
            "        [[0.8444, 0.2941],\n",
            "         [0.8444, 0.2941],\n",
            "         [0.8444, 0.2941]],\n",
            "\n",
            "        [[0.8444, 0.2941],\n",
            "         [0.8444, 0.2941],\n",
            "         [0.8444, 0.2941]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the example above\n",
        "\n",
        "The multiplication operation that created (b) was broadcast over every “layer” of (a).\n",
        "\n",
        "For (c), the operation was broadcast over ever layer and row of (a) - every 3-element column is identical.\n",
        "\n",
        "For (d), we switched it around - now every row is identical, across layers and columns.\n"
      ],
      "metadata": {
        "id": "f6MOWxlYN72T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For more samples of Math operations\n",
        "PyTorch has more the 300 operations type\n",
        "check out the documentation: https://pytorch.org/docs/stable/torch.html#math-operations"
      ],
      "metadata": {
        "id": "UcJDCv_zRelV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Altering Tensors in Place\n",
        "\n",
        "most binary operations on tensors will return a third, new tensor.\n",
        "When we say c = a * b (where a and b are tensors), the new tensor c will occupy a region of memory distinct from the other tensors.\n",
        "\n",
        "there will be times that I wish to alter a tensor in place, for example: if I'm doing a element-wise computation where I can discard intermediate values. For this, most of the math functions have a version with an appended underscore(_) that will alter a tensor in place."
      ],
      "metadata": {
        "id": "jIS_hb4UR-Wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
        "print('a:')\n",
        "print(a)\n",
        "print(torch.sin(a)) # this operation creates a new tensor in memory\n",
        "print(a) # a has not changed\n",
        "\n",
        "b = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
        "print('\\nb:')\n",
        "print(b)\n",
        "print(torch.sin_(b)) # with underscore\n",
        "print(b) # b has changed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90pVoBc2S6jr",
        "outputId": "c5e8256b-580e-4d71-f998-86c223540c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a:\n",
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
            "\n",
            "b:\n",
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for arithmetic  operations, there are functions that behave similarly:\n",
        "\n",
        "a = torch.ones(2, 2)\n",
        "b = torch.rand(2, 2)\n",
        "\n",
        "print('Before:')\n",
        "print(a)\n",
        "print(b)\n",
        "print('\\nAfter adding:')\n",
        "print(a.add_(b))\n",
        "print(a)\n",
        "print(b)\n",
        "print('\\nAfter multiplying:')\n",
        "print(b.mul_(b))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAJZ8Ha3W_CU",
        "outputId": "aa4550c4-6a7a-4f78-9c8c-a9e4bf2d4f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0.3788, 0.4567],\n",
            "        [0.0649, 0.6677]])\n",
            "\n",
            "After adding:\n",
            "tensor([[1.3788, 1.4567],\n",
            "        [1.0649, 1.6677]])\n",
            "tensor([[1.3788, 1.4567],\n",
            "        [1.0649, 1.6677]])\n",
            "tensor([[0.3788, 0.4567],\n",
            "        [0.0649, 0.6677]])\n",
            "\n",
            "After multiplying:\n",
            "tensor([[0.1435, 0.2086],\n",
            "        [0.0042, 0.4459]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "these in- place arithmetic functionsyou  can see that the calling tensor is the one that gets changed in place"
      ],
      "metadata": {
        "id": "3fR9lY3sX_Pp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# another option for placing the result of a computation in an existing, allocated tensor\n",
        "\n",
        "a = torch.rand(2, 2)\n",
        "b = torch.rand(2, 2)\n",
        "c = torch.zeros(2, 2)\n",
        "old_id = id(c)\n",
        "\n",
        "print(c)\n",
        "\n",
        "d = torch.matmul(a, b, out=c)\n",
        "print(c) # content of c have changes\n",
        "\n",
        "assert c is d # test c & d are same object, not just containing equal values\n",
        "assert id(c) == old_id # make sure that our new c is the same object as the old one\n",
        "\n",
        "torch.rand(2, 2, out=c) # works for creation too\n",
        "print(c) # c has change again\n",
        "assert id(c) == old_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubkR8treYhx0",
        "outputId": "251b3661-e7c1-48f4-c0f1-04b69a2bb89f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[0.3653, 0.8699],\n",
            "        [0.2364, 0.3604]])\n",
            "tensor([[0.0776, 0.4004],\n",
            "        [0.9877, 0.0352]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copying Tensors\n",
        "As with any object in Python, assigning a tensor to a variable makes the variable a label of the tensor, and does not copy it. For example:"
      ],
      "metadata": {
        "id": "0GXDHuKvZmvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(2, 2)\n",
        "b = a\n",
        "\n",
        "a[0][1] = 516 # we change a...\n",
        "print(b) # be is also altered"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWNHOLUHZ0-Q",
        "outputId": "6595b0f6-d65a-4082-b827-c0a6795edf38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  1., 516.],\n",
            "        [  1.,   1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If I want to separate copy of the data to work on, I should use the ``clone()`` method"
      ],
      "metadata": {
        "id": "L3TpFLwYaJE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(2, 2)\n",
        "b = a.clone()\n",
        "\n",
        "assert b is not a # different objects in memory\n",
        "print(torch.eq(a, b)) #but still with the same contents\n",
        "\n",
        "a[0][1] = 516 # a chenged\n",
        "print(b) # b still ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NFdqdDCaVvn",
        "outputId": "96e55f75-e167-4ccf-81a2-d029a26a7104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[True, True],\n",
            "        [True, True]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if I clone a variable, its autograd clone too\n",
        "in this case I can use ``.detach()`` method on the souce tensor"
      ],
      "metadata": {
        "id": "z28iHfE6bTF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(2, 2, requires_grad=True) # Turn on the autograd\n",
        "print(a)\n",
        "\n",
        "b = a.clone() # clone the autograd too\n",
        "print(b)\n",
        "\n",
        "c = a.detach().clone() # detach method detaches the tensor from its computation history\n",
        "print(c) # c has no autograd due the detach\n",
        "\n",
        "print(a) # a has not been altered, so it still has autograd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KKue4OSboAZ",
        "outputId": "90e27eeb-5139-4a73-de2d-5fb15366e5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0905, 0.4485],\n",
            "        [0.8740, 0.2526]], requires_grad=True)\n",
            "tensor([[0.0905, 0.4485],\n",
            "        [0.8740, 0.2526]], grad_fn=<CloneBackward0>)\n",
            "tensor([[0.0905, 0.4485],\n",
            "        [0.8740, 0.2526]])\n",
            "tensor([[0.0905, 0.4485],\n",
            "        [0.8740, 0.2526]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving to GPU"
      ],
      "metadata": {
        "id": "KlGSo6S8csI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  print('We have GPU!')\n",
        "else:\n",
        "  print('Sorry, CPU only')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HklJkBBc0Q7",
        "outputId": "b82046f2-9f80-449c-f312-6fdf6cf45386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have GPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# There are multiple ways to get your data onto your target device. You may do it at creation time:\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  gpu_rand = torch.rand(2, 2, device='cuda')\n",
        "  print(gpu_rand)\n",
        "else:\n",
        "  print('sorry, CPU only')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbtn4YHldjGA",
        "outputId": "1ff5c61a-6029-44b3-da0b-cffc773c5c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3344, 0.2640],\n",
            "        [0.2119, 0.0582]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, new tensors are created on the CPU\n",
        "\n",
        "Lest's create a device handle that can be passed to my tensor instead of a string"
      ],
      "metadata": {
        "id": "KpBgm98SeEdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  my_device = torch.device('cuda')\n",
        "else:\n",
        "  my_device = torch.device('cpu')\n",
        "print(f'Device {my_device}')\n",
        "\n",
        "x = torch.rand(2, 2, device=my_device)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "352NkSeNeYVg",
        "outputId": "db541260-f824-4ad9-df53-17cc895b34a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cuda\n",
            "tensor([[0.0024, 0.6778],\n",
            "        [0.2441, 0.6812]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If I have a existing tensor living on one device, I can move to another using ``to()`` method"
      ],
      "metadata": {
        "id": "8zsoTqBLfDIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.rand(2, 2)\n",
        "y = y.to(my_device)\n",
        "\n",
        "# Remember that the tensors should be in the same device for operations\n"
      ],
      "metadata": {
        "id": "FX2IcrUcfNOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulating Tensor Shapes\n",
        "\n",
        "sometimes, you'll  need to change the shapes of your tensor"
      ],
      "metadata": {
        "id": "bxsMXl-vfqFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Changing the number of dimensions"
      ],
      "metadata": {
        "id": "mVA56v6vf63E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(3, 226, 226)\n",
        "b = a.unsqueeze(0)\n",
        "\n",
        "print(a.shape)\n",
        "print(b.shape) # if it was a image, now we have the batch dimension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEYoc7VpgHPQ",
        "outputId": "f2d3683b-09f8-4835-9eb7-a05658f72736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 226, 226])\n",
            "torch.Size([1, 3, 226, 226])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The unsqueeze() method adds a dimension of extent 1. unsqueeze(0) adds it as a new zeroth dimension - now you have a batch of one"
      ],
      "metadata": {
        "id": "frDzqmU_gpMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(1, 20)\n",
        "print(a.shape)\n",
        "print(a)\n",
        "\n",
        "b = a.squeeze(0)\n",
        "print(b.shape)\n",
        "print(b)\n",
        "\n",
        "c = torch.rand(2, 2)\n",
        "print(c.shape)\n",
        "\n",
        "d = c.squeeze(0) # The squeeze don't afcted the shape because it only act on dimensions of extend 1\n",
        "print(d.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnZIT9_Mid2a",
        "outputId": "f227f3f5-ea57-41b3-cd56-7f8e41fd3e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 20])\n",
            "tensor([[0.2347, 0.1899, 0.4067, 0.1519, 0.1506, 0.9585, 0.7756, 0.8973, 0.4929,\n",
            "         0.2367, 0.8194, 0.4509, 0.2690, 0.8381, 0.8207, 0.6818, 0.5057, 0.9335,\n",
            "         0.9769, 0.2792]])\n",
            "torch.Size([20])\n",
            "tensor([0.2347, 0.1899, 0.4067, 0.1519, 0.1506, 0.9585, 0.7756, 0.8973, 0.4929,\n",
            "        0.2367, 0.8194, 0.4509, 0.2690, 0.8381, 0.8207, 0.6818, 0.5057, 0.9335,\n",
            "        0.9769, 0.2792])\n",
            "torch.Size([2, 2])\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if the random vector had just been 3-element vector? We'd lose the ability to do the broadcast, because the final dimensions would not match up according to the broadcasting rules. unsqueeze() comes to the rescue:"
      ],
      "metadata": {
        "id": "yqZi5lyVlyXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(4, 3, 2)\n",
        "b = torch. rand(3) # trying to multiply a * b will give a runtime error\n",
        "c = b.unsqueeze(1) # The number 1 is the place of the new dimension\n",
        "print(c.shape)\n",
        "print(a * c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcmh7Wadl1OR",
        "outputId": "bc679dcd-5c4c-466e-cd0f-2c9b51ecb214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1])\n",
            "tensor([[[0.8625, 0.8625],\n",
            "         [0.6191, 0.6191],\n",
            "         [0.9935, 0.9935]],\n",
            "\n",
            "        [[0.8625, 0.8625],\n",
            "         [0.6191, 0.6191],\n",
            "         [0.9935, 0.9935]],\n",
            "\n",
            "        [[0.8625, 0.8625],\n",
            "         [0.6191, 0.6191],\n",
            "         [0.9935, 0.9935]],\n",
            "\n",
            "        [[0.8625, 0.8625],\n",
            "         [0.6191, 0.6191],\n",
            "         [0.9935, 0.9935]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unsqueeze and squeeze in-place version\n",
        "\n",
        "batch_me = torch.rand(3, 226, 226)\n",
        "print(batch_me.shape)\n",
        "batch_me.unsqueeze_(0)\n",
        "print(batch_me.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h978E-_3mhys",
        "outputId": "d0f76a5b-8045-4178-e4d3-7d8712674ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 226, 226])\n",
            "torch.Size([1, 3, 226, 226])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# redmensioning a tensor (image to 1 dimensional)\n",
        "\n",
        "output3d = torch.rand(6, 20, 20)\n",
        "print(output3d.shape)\n",
        "\n",
        "input1d = output3d.reshape(6 * 20 * 20)\n",
        "print(input1d.shape)\n",
        "\n",
        "# can also call it as a method on the torch module:\n",
        "print(torch.reshape(output3d, (6 * 20 * 20,)).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I73F5GAQpmiB",
        "outputId": "4016ee76-916b-439e-9ebe-c62fef46390b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 20, 20])\n",
            "torch.Size([2400])\n",
            "torch.Size([2400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numpy Bridge\n",
        "\n",
        "Switching between ndarrays and PyTorch tensors:"
      ],
      "metadata": {
        "id": "wsA5-cqyqtPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "numpy_array = np.ones((2, 3))\n",
        "print(numpy_array)\n",
        "\n",
        "pytorch_tensor = torch.from_numpy(numpy_array)\n",
        "print(pytorch_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw3YfaL8rDZu",
        "outputId": "85459615-80cb-4018-9b03-a2a642b5f6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]]\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch creates a tensor of the same shape and data as numpy\n",
        "float64 is the numpy default"
      ],
      "metadata": {
        "id": "iCi72lrrrmb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_rand = torch.rand(2, 3)\n",
        "print(pytorch_rand)\n",
        "\n",
        "numpy_rand = pytorch_rand.numpy()\n",
        "print(numpy_rand)\n",
        "print(numpy_rand.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1eHdfKJr1A2",
        "outputId": "de08e0a6-570b-431d-9f03-16b04862a5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3465, 0.1790, 0.8715],\n",
            "        [0.5255, 0.1814, 0.2284]])\n",
            "[[0.34647584 0.17902076 0.87154263]\n",
            " [0.52549195 0.18138081 0.22844744]]\n",
            "float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Theses converted objects are using the same inderlying memory as their souce objects\n",
        "# meaning that changes to one are reflected in the other:\n",
        "\n",
        "numpy_array[1, 1] = 23\n",
        "print(pytorch_tensor)\n",
        "\n",
        "pytorch_rand[1, 1] = 17\n",
        "print(numpy_rand)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFThFUpIsWF6",
        "outputId": "d90894a8-941e-4670-90ec-fb4e9af49cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.,  1.,  1.],\n",
            "        [ 1., 23.,  1.]], dtype=torch.float64)\n",
            "[[ 0.34647584  0.17902076  0.87154263]\n",
            " [ 0.52549195 17.          0.22844744]]\n"
          ]
        }
      ]
    }
  ]
}