{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1G787pCQ0tw81unYYxo63",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Renan-Domingues/IntroductionToPytorch/blob/main/IntroductionPytorch_05_TensorboardSupport.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch TensorBoard Support\n"
      ],
      "metadata": {
        "id": "ZJDG-onwanKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction\n",
        "This is a varient of the LeNet-5 against Fashion-MNIST dataset."
      ],
      "metadata": {
        "id": "RbDLKfSnawGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch model and training necessities\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Image datasets and image manipulation\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# image display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# pytorch TensorBoard support\n",
        "from torch.utils.tensorboard import SummaryWriter\n"
      ],
      "metadata": {
        "id": "Y5YC5tWqbAsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding  sample images from our dataset to Tensorboard\n",
        "\n",
        "# Gather datasets and prepare them for consumption\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))]\n",
        ")\n",
        "\n",
        "# Store separate training and validations splits in. /data\n",
        "training_set = torchvision.datasets.FashionMNIST('.data',\n",
        "                                                 download=True,\n",
        "                                                 train=True,\n",
        "                                                 transform=transform)\n",
        "validation_set = torchvision.datasets.FashionMNIST('./data',\n",
        "                                                   download=True,\n",
        "                                                   train=False,\n",
        "                                                   transform=transform)\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(training_set,\n",
        "                                              batch_size=4,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=2)\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set,\n",
        "                                                batch_size=4,\n",
        "                                                shuffle=False,\n",
        "                                                num_workers=2)\n",
        "\n",
        "# class labels\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "# Helper function for inline image display\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "  if one_channel:\n",
        "    img = img.mean(dim=0)\n",
        "  img = img / 2 + 0.5 # unnormalize\n",
        "  npimg = img.numpy()\n",
        "  if one_channel:\n",
        "    plt.imshow(npimg, cmap=\"Greys\")\n",
        "  else:\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "# Extract a batch of 4 images\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Create a grid from the images and show them\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "matplotlib_imshow(img_grid, one_channel=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "BOXViAfecktg",
        "outputId": "d3ab6413-4926-4355-c733-cfa6401f8e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, we used TorchVisiond and Matplotlib to create a visual grid of minibatch of our imput data.\n",
        "\n",
        "Now we'll going to use \"add_image()\" call on \"SummaryWriter\" to log the image for consumption by TensorBoard, and we'll also call \"flush()\" to  make sure it's written to disk right away"
      ],
      "metadata": {
        "id": "h28epfaVh066"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Default log_dir argument is \"runs\" - but it's good to be specific\n",
        "# torch.utils.tensorboard.SummaryWriter is alredy imported\n",
        "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
        "\n",
        "# Write image data to TensorBoard log dir\n",
        "writer.add_image('Four Fashion_MNIST Images', img_grid)\n",
        "writer.flush()\n",
        "\n",
        "# To view, start TensorBoard on the command line with:\n",
        "#   tensorboard --logdir=runs\n",
        "# ...and open a browser tab to http://localhost:6006/"
      ],
      "metadata": {
        "id": "KRVLDAhxio6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you start TensorBoard at the command line and open it in a new browser tab (usually at localhost:6006), you should see the image grid under the IMAGES tab."
      ],
      "metadata": {
        "id": "4PBN1ZV1jmQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graphing Scalars to Visualize Training\n",
        "\n",
        "We'll run a training loop, track some metrics, and save the data for TensorBoard's consumption."
      ],
      "metadata": {
        "id": "WmrUm45xjwox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a model  to categorize out image tiles, and a optimizer and loss function for training\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16 * 4 * 4)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "FQUyFA-BlUEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's train a epoch and evaluate the training vs. validation set losses every 1000 batches\n",
        "\n",
        "print(len(validation_loader))\n",
        "\n",
        "for epoch in range(1): # loop over the dataset multiple times\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for i, data in enumerate(training_loader, 0):\n",
        "    # basic training loop\n",
        "    inputs, labels = data\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % 1000 == 999: # every 1000 minibatches\n",
        "      print(f\"Batch {i + 1}\")\n",
        "      # check against the validation set\n",
        "      running_vloss = 0.0\n",
        "\n",
        "      net.train(False) # Don't need to track gradents for validation\n",
        "      for j, vdata in enumerate(validation_loader, 0):\n",
        "        vinputs, vlabels = vdata\n",
        "        voutputs = net(vinputs)\n",
        "        vloss = criterion(voutputs, vlabels)\n",
        "        running_vloss += vloss.item()\n",
        "      net.train(True) # Turn gradients back on for training\n",
        "\n",
        "      avg_loss = running_loss / 1000\n",
        "      avg_vloss = running_vloss / len(validation_loader)\n",
        "\n",
        "      # log the running loss averaged per batch\n",
        "      writer.add_scalars('Training vs. Validation Loss',\n",
        "                         {'Training': avg_loss, 'Validation': avg_vloss},\n",
        "                         epoch * len(training_loader) + i)\n",
        "      running_loss = 0.0\n",
        "print('Finished Training')\n",
        "\n",
        "writer.flush()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMk15Kl6nPNO",
        "outputId": "586ae98e-6dbf-4c20-f920-121a95c5c56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500\n",
            "Batch 1000\n",
            "Batch 2000\n",
            "Batch 3000\n",
            "Batch 4000\n",
            "Batch 5000\n",
            "Batch 6000\n",
            "Batch 7000\n",
            "Batch 8000\n",
            "Batch 9000\n",
            "Batch 10000\n",
            "Batch 11000\n",
            "Batch 12000\n",
            "Batch 13000\n",
            "Batch 14000\n",
            "Batch 15000\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing Your Model\n",
        "\n",
        "TensorBoard can also be used to examine the data flow within your model. To do this, call the \"add_graph()\" method with a model and sample input. When you open"
      ],
      "metadata": {
        "id": "IHKc6qxdr4RQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# grab a single minibatch of image\n",
        "dataiter = iter(training_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# add_graph() will trace the sample input through my model and render it as a graph\n",
        "writer.add_graph(net, images)\n",
        "writer.flush()\n"
      ],
      "metadata": {
        "id": "TQ4DWZEVsEWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Double-click the “NET” node to see the layers and data flow within my model."
      ],
      "metadata": {
        "id": "S2U5F2Xgs1BM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing My Dataset with\n",
        "\n",
        "The 28-by-28 image tiles we're using can be modeled as 784-dimensional vectors (28 * 28 = 784).\n",
        "\n",
        "The \"add_embedding()\" method will project a set of data onto the three dimensions with highest variance, and display them as an interactive 3D chart.  The \"add_embedding()\" do this automatically\n",
        "\n",
        "Let's generate such an ambedding:\n"
      ],
      "metadata": {
        "id": "MuPZlETqs4oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a random subset of data and corresponding labels\n",
        "\n",
        "def select_n_random(data, labels, n=100):\n",
        "  assert len(data) == len(labels)\n",
        "\n",
        "  perm = torch.randperm(len(data))\n",
        "  return data[perm][:n], labels[perm][:n]\n",
        "\n",
        "# extract a random sibset of data\n",
        "images, labels = select_n_random(training_set.data, training_set.targets)\n",
        "\n",
        "# get the class labels for each image\n",
        "class_labels = [classes[label] for label in labels]\n",
        "\n",
        "# log embeddings\n",
        "features = images.view(-1, 28 * 28)\n",
        "writer.add_embedding(features,\n",
        "                    metadata=class_labels,\n",
        "                    label_img=images.unsqueeze(1))\n",
        "\n",
        "writer.flush()\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "A0CJ76PGtqYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now if I switch to TensorBoard and select the PROJECTOR tab, I should see a 3D representation of the projection."
      ],
      "metadata": {
        "id": "_qJ4K5YovD72"
      }
    }
  ]
}